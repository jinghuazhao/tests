{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import numpy as np\n",
        "\n",
        "class CustomCallback(Callback):\n",
        "    def on_train_begin(self, logs=None):\n",
        "        print(\"Starting training...\")\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        print(\"Finished training.\")\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        print(f\"Starting epoch {epoch}\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"Finished epoch {epoch}\")\n",
        "        print(f\"Train loss: {logs['loss']}\")\n",
        "\n",
        "    def on_train_batch_begin(self, batch, logs=None):\n",
        "        print(f\"Training: Starting batch {batch}\")\n",
        "\n",
        "    def on_train_batch_end(self, batch, logs=None):\n",
        "        print(f\"Training: Finished batch {batch}\")\n",
        "        print(f\"Train loss: {logs['loss']}\")\n",
        "\n",
        "    def on_test_begin(self, logs=None):\n",
        "        print(\"Starting testing...\")\n",
        "\n",
        "    def on_test_end(self, logs=None):\n",
        "        print(\"Finished testing.\")\n",
        "\n",
        "    def on_test_batch_begin(self, batch, logs=None):\n",
        "        print(f\"Testing: Starting batch {batch}\")\n",
        "\n",
        "    def on_test_batch_end(self, batch, logs=None):\n",
        "        print(f\"Testing: Finished batch {batch}\")\n",
        "        print(f\"Test loss: {logs['loss']}\")\n",
        "\n",
        "# Custom Loss\n",
        "def custom_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "# Model\n",
        "inputA = Input(shape=(32,))\n",
        "inputB = Input(shape=(100,))\n",
        "\n",
        "# For inputA\n",
        "x = Embedding(input_dim=10000, output_dim=64)(inputA)\n",
        "x = Flatten()(x)\n",
        "x = Dense(16, activation='relu', kernel_initializer='he_normal')(x)\n",
        "x = Model(inputs=inputA, outputs=x)\n",
        "\n",
        "# For inputB\n",
        "y = Dense(64, activation='sigmoid', kernel_initializer='glorot_uniform')(inputB)\n",
        "y = Model(inputs=inputB, outputs=y)\n",
        "\n",
        "combined = Concatenate()([x.output, y.output])\n",
        "\n",
        "z = Dense(10, activation=\"linear\")(combined)\n",
        "z = Dense(1, activation=\"sigmoid\")(z)\n",
        "\n",
        "model = Model(inputs=[x.input, y.input], outputs=z)\n",
        "model.compile(loss=custom_loss, optimizer=\"adam\")\n",
        "\n",
        "# Data\n",
        "num_samples = 1000\n",
        "inputA_data = np.random.randint(10000, size=(num_samples, 32))\n",
        "inputB_data = np.random.rand(num_samples, 100)\n",
        "labels = np.random.randint(2, size=(num_samples, 1))\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit([inputA_data, inputB_data], labels, epochs=50, callbacks=[CustomCallback()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSL7haQ_lp15",
        "outputId": "6417be8e-530c-415a-c900-2cafbd8366b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Training: Finished batch 16\n",
            "Train loss: 0.2939537465572357\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 0.29223236441612244\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 0.289949893951416\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 0.28836241364479065\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 0.28642645478248596\n",
            "\u001b[1m21/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3321Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 0.28447434306144714\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 0.28276416659355164\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 0.28150245547294617\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 0.2808447778224945\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 0.2797616720199585\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 0.27974972128868103\n",
            "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3209Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 0.27827805280685425\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 0.27768975496292114\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 0.277269572019577\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 0.27671942114830017\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 0.27639809250831604\n",
            "Finished epoch 0\n",
            "Train loss: 0.27639809250831604\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.3129\n",
            "Starting epoch 1\n",
            "Epoch 2/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 0.2328970581293106\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 235ms/step - loss: 0.2329Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 0.23599989712238312\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 0.23557378351688385\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 0.23500025272369385\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 0.23621301352977753\n",
            "\u001b[1m 5/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2351 Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 0.2335202544927597\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 0.23321452736854553\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 0.23206359148025513\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 0.2316814512014389\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 0.2309909164905548\n",
            "\u001b[1m10/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2337Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 0.230991929769516\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 0.2300940752029419\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 0.22950336337089539\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 0.22918133437633514\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 0.22837716341018677\n",
            "\u001b[1m15/32\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2324Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 0.2270020842552185\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 0.22619330883026123\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 0.22493992745876312\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 0.224239319562912\n",
            "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2309Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 0.224185973405838\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 0.22392095625400543\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 0.2237982153892517\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 0.22324222326278687\n",
            "\u001b[1m23/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2297Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 0.2224835604429245\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 0.22178754210472107\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 0.22107237577438354\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 0.21992427110671997\n",
            "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2284Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 0.2190181463956833\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 0.21825745701789856\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 0.2175075113773346\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 0.21668273210525513\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2271Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 0.21636298298835754\n",
            "Finished epoch 1\n",
            "Train loss: 0.21636298298835754\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.2264\n",
            "Starting epoch 2\n",
            "Epoch 3/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 0.14133986830711365\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.1413Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 0.13598951697349548\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 0.13314323127269745\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 0.13475453853607178\n",
            "\u001b[1m 4/32\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1363Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 0.13308663666248322\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 0.13082891702651978\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 0.12834542989730835\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 0.12661851942539215\n",
            "\u001b[1m 8/32\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1330Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 0.1237168163061142\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 0.12284084409475327\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 0.12031569331884384\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 0.11869024485349655\n",
            "\u001b[1m12/32\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.1291Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 0.1161046028137207\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 0.11417730152606964\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 0.11207190155982971\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 0.1089191809296608\n",
            "\u001b[1m16/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1251Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 0.10665909200906754\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 0.10424353927373886\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 0.10302166640758514\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 0.10103483498096466\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1208Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 0.09883041679859161\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 0.09665589779615402\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 0.09440870583057404\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 0.09276659041643143\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1166Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 0.09104422479867935\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 0.08914517611265182\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 0.08702196925878525\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 0.0851409062743187\n",
            "\u001b[1m28/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1125Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 0.08341354876756668\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 0.08169800788164139\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 0.08019354194402695\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 0.07977417856454849\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.1086Finished epoch 2\n",
            "Train loss: 0.07977417856454849\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.1078\n",
            "Starting epoch 3\n",
            "Epoch 4/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 0.006721454206854105\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0067Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 0.005568802356719971\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 0.005581640172749758\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 0.005293456371873617\n",
            "\u001b[1m 4/32\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0058 Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 0.004939219914376736\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 0.004504125099629164\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 0.004308158066123724\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 0.004163658246397972\n",
            "\u001b[1m 8/32\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0051Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 0.0039609819650650024\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 0.0038256128318607807\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 0.0037195717450231314\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 0.0035240210127085447\n",
            "\u001b[1m12/32\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0047Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 0.003378593595698476\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 0.003286156104877591\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 0.0031737552490085363\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 0.003060606773942709\n",
            "\u001b[1m16/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0043Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 0.0029423448722809553\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 0.002841284265741706\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 0.0027544694021344185\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 0.0026662484742701054\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0040Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 0.0026110049802809954\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 0.002540660323575139\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 0.0024813369382172823\n",
            "\u001b[1m23/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0038Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 0.002410897286608815\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 0.0023511408362537622\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 0.002297440078109503\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 0.0022435912396758795\n",
            "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0036Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 0.002210898557677865\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 0.0021658632904291153\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 0.0021404274739325047\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 0.002096371492370963\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0034Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 0.0020844563841819763\n",
            "Finished epoch 3\n",
            "Train loss: 0.0020844563841819763\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0033\n",
            "Starting epoch 4\n",
            "Epoch 5/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 0.0007770704687573016\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - loss: 7.7707e-04Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 0.0007611546898260713\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 0.0007809909875504673\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 0.0007541022496297956\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 0.0007010202389210463\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 0.000675894960295409\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 0.0006612451397813857\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3021e-04  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 0.0006463261088356376\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 0.0006500444142147899\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 0.0006384998559951782\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 0.0006243622628971934\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 0.0006176720489747822\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 0.000602956220973283\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.8395e-04Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 0.0005987637559883296\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 0.0006035519763827324\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 0.000596311001572758\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 0.0005890848115086555\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 0.0005746368551626801\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 0.0005730537814088166\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 0.0005696536391042173\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4982e-04Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 0.0005642249598167837\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 0.0005603218451142311\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 0.0005541855935007334\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 0.0005478630773723125\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 0.000543886621017009\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 0.0005409371806308627\n",
            "\u001b[1m26/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.2722e-04Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 0.0005346129182726145\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 0.0005321490461938083\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 0.0005330046988092363\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 0.0005305327940732241\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 0.0005272728158161044\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 0.0005265026702545583\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0912e-04Finished epoch 4\n",
            "Train loss: 0.0005265026702545583\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0662e-04\n",
            "Starting epoch 5\n",
            "Epoch 6/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 0.00044640019768849015\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 4.4640e-04Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 0.00040106571395881474\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 0.000434284214861691\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 0.00041333562694489956\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 0.0004181000404059887\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 0.0004013185389339924\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 0.0003936679568141699\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1545e-04 Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 0.0003932653635274619\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 0.0003912534739356488\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 0.0003860537544824183\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 0.00038080353988334537\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 0.00037552157300524414\n",
            "\u001b[1m12/32\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.0292e-04Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 0.00037755334051325917\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 0.0003777906240429729\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 0.0003783316060435027\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 0.0003804512380156666\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 0.0003782513667829335\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 0.00037378945853561163\n",
            "\u001b[1m18/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9451e-04 Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 0.00036832940531894565\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 0.0003677980857901275\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 0.0003666216507554054\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 0.00036653189454227686\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 0.000366354564903304\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 0.00036628369707614183\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8763e-04Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 0.000364673906005919\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 0.0003640102513600141\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 0.00036199070746079087\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 0.0003605866804718971\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 0.0003580966149456799\n",
            "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.8319e-04Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 0.0003568089450709522\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 0.0003554681607056409\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 0.00035554455826058984\n",
            "Finished epoch 5\n",
            "Train loss: 0.00035554455826058984\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.7988e-04\n",
            "Starting epoch 6\n",
            "Epoch 7/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 0.0003325757570564747\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 293ms/step - loss: 3.3258e-04Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 0.00032563472632318735\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 0.0002995239628944546\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 0.0002990899665746838\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 0.00028850664966739714\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 0.00028145135729573667\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 0.000285477057332173\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.0175e-04  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 0.00028273300267755985\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 0.00027873285580426455\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 0.0002750516578089446\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 0.0002738408511504531\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 0.0002796299522742629\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 0.0002807681739795953\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 0.0002817651256918907\n",
            "\u001b[1m14/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.9034e-04Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 0.00027789175510406494\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 0.00027864190633408725\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 0.0002782924857456237\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 0.0002790223516058177\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 0.00027708281413652003\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 0.00027778572984971106\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.8667e-04Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 0.0002776897163130343\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 0.0002777756017167121\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 0.000277937127975747\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 0.00027608044911175966\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 0.00027613990823738277\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 0.0002755735768005252\n",
            "\u001b[1m26/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8441e-04Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 0.00027420386322773993\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 0.0002727301907725632\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 0.0002724654332268983\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 0.00027066809707321227\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 0.00027111941017210484\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 0.00027075785328634083\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8208e-04Finished epoch 6\n",
            "Train loss: 0.00027075785328634083\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.8174e-04\n",
            "Starting epoch 7\n",
            "Epoch 8/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 0.0002769620041362941\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 2.7696e-04Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 0.00024769449373707175\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 0.000227163836825639\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 0.0002248575765406713\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 0.00022205051209311932\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 0.00022322707809507847\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3699e-04Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 0.0002300056366948411\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 0.00022483314387500286\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 0.00022415480634663254\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 0.00022749688650947064\n",
            "\u001b[1m10/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.3284e-04Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 0.00022603503020945936\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 0.00022728655312675983\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 0.0002261116314912215\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 0.00022434366110246629\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 0.0002235154970549047\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 0.00022288825130090117\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 0.00022324635938275605\n",
            "\u001b[1m17/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.2952e-04Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 0.00022333984088618308\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 0.00022235857613850385\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 0.00022195260680746287\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 0.00022074363369029015\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 0.00022064610675442964\n",
            "\u001b[1m22/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2777e-04Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 0.00021990120876580477\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 0.00021938492136541754\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 0.00022016266302671283\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 0.00022060718038119376\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 0.0002187106729252264\n",
            "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.2628e-04Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 0.00021775865752715617\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 0.00021659707999788225\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 0.0002161138691008091\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 0.00021526870841626078\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 0.000214664833038114\n",
            "Finished epoch 7\n",
            "Train loss: 0.000214664833038114\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2439e-04\n",
            "Starting epoch 8\n",
            "Epoch 9/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 0.0002279245964018628\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 277ms/step - loss: 2.2792e-04Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 0.0002105378662236035\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 0.00019988759595435113\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 0.0001958159846253693\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 0.00019675513613037765\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 0.00019396422430872917\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.0415e-04 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 0.00019443317432887852\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 0.00019273092038929462\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 0.00019173805776517838\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 0.00018942482711281627\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 0.00018822062702383846\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 0.00018824632570613176\n",
            "\u001b[1m12/32\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9747e-04Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 0.0001894504966912791\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 0.00019097990298178047\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 0.00018889961938839406\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 0.0001872008724603802\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 0.00018583568453323096\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 0.0001849808031693101\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 0.0001831070549087599\n",
            "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9369e-04 Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 0.00018185999942943454\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 0.00018172390991821885\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 0.00018148348317481577\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 0.00018163320783060044\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 0.00018147069204133004\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 0.00018026231555268168\n",
            "\u001b[1m25/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9074e-04Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 0.00017881828534882516\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 0.00017778215988073498\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 0.00017634454707149416\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 0.000175131659489125\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 0.0001750786032062024\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8839e-04Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 0.00017515898798592389\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 0.0001749013754306361\n",
            "Finished epoch 8\n",
            "Train loss: 0.0001749013754306361\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.8717e-04\n",
            "Starting epoch 9\n",
            "Epoch 10/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 0.0001331439707428217\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 301ms/step - loss: 1.3314e-04Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 0.00014409780851565301\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 0.00014731277769897133\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 0.0001483793166698888\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 0.00014973765064496547\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 0.00015232240548357368\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 0.00015368298045359552\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 0.00015038359561003745\n",
            "\u001b[1m 8/32\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4738e-04  Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 0.00014815881149843335\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 0.00014681719767395407\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 0.00014900030510034412\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 0.0001472948642913252\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 0.00014758729957975447\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 0.00014701577310916036\n",
            "\u001b[1m14/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4750e-04Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 0.0001463457301724702\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 0.00014660440501756966\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 0.00014703073247801512\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 0.00014748744433745742\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 0.00014788529369980097\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 0.00014671201643068343\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4735e-04Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 0.0001466858811909333\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 0.00014533899957314134\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 0.00014548187027685344\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 0.00014583846495952457\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 0.00014555019151885062\n",
            "\u001b[1m25/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4704e-04Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 0.00014676523278467357\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 0.000146418358781375\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 0.00014634437684435397\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 0.00014611145888920873\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 0.0001456134341424331\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 0.00014520464173983783\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4685e-04Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 0.0001450575509807095\n",
            "Finished epoch 9\n",
            "Train loss: 0.0001450575509807095\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 1.4674e-04\n",
            "Starting epoch 10\n",
            "Epoch 11/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 0.00013467040844261646\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 308ms/step - loss: 1.3467e-04Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 0.0001368971134070307\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 0.00013193389168009162\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 0.00012923491885885596\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 0.00012756245268974453\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 0.00012646487448364496\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 0.00012441213766578585\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3017e-04  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 0.00012355463695712388\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 0.00012244642130099237\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 0.00012639196938835084\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 0.0001264022575924173\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 0.00012652171426452696\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 0.00012739907833747566\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2799e-04Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 0.00012506595521699637\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 0.00012465582403820008\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 0.0001249207998625934\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 0.00012471599620766938\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 0.00012444451567716897\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 0.00012487091589719057\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 0.00012469801004044712\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2686e-04Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 0.00012389800394885242\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 0.0001231166097568348\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 0.00012282819079700857\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 0.00012299900117795914\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 0.00012307231372687966\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 0.00012288798461668193\n",
            "\u001b[1m26/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2600e-04Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 0.00012294524640310556\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 0.00012327564763836563\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 0.00012367434101179242\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 0.0001231236819876358\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2564e-04Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 0.00012241074000485241\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 0.0001224228326464072\n",
            "Finished epoch 10\n",
            "Train loss: 0.0001224228326464072\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.2534e-04\n",
            "Starting epoch 11\n",
            "Epoch 12/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 0.00013878164463676512\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 1.3878e-04Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 0.00012386425805743784\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 0.0001200642655021511\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 0.0001151914766523987\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 0.00011666514910757542\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 0.00011479695240268484\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2156e-04Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 0.00011680224270094186\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 0.00011293090938124806\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 0.00011286212975392118\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 0.00011209058720851317\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 0.00011194185935892165\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 0.00011105582234449685\n",
            "\u001b[1m12/32\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1725e-04Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 0.00010959109204122797\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 0.00010917654435615987\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 0.00010870697587961331\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 0.00010856303561013192\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 0.00010780796583276242\n",
            "\u001b[1m17/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1476e-04Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 0.00010743535676738247\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 0.00010671776544768363\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 0.0001061385846696794\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 0.00010580294474493712\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 0.0001057657427736558\n",
            "\u001b[1m22/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1285e-04Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 0.00010582712275208905\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 0.00010527632548473775\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 0.00010505467071197927\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 0.00010506664693821222\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 0.00010482608922757208\n",
            "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1144e-04Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 0.00010510314314160496\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 0.00010517849295865744\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 0.00010501664655748755\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 0.00010496626782696694\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 0.00010476943134563044\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1043e-04Finished epoch 11\n",
            "Train loss: 0.00010476943134563044\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.1026e-04\n",
            "Starting epoch 12\n",
            "Epoch 13/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 9.35076386667788e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 274ms/step - loss: 9.3508e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 0.00010521974763832986\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 9.953108383342624e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 9.829163900576532e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 9.99529511318542e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 9.886177576845512e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 9.881297592073679e-05\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.9168e-05  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 9.834263619268313e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 9.85612059594132e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 9.959724411601201e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 9.897624113364145e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 9.703332762001082e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 9.548723755870014e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.8629e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 9.457586565986276e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 9.386325109517202e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 9.414889791514724e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 9.409472841070965e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 9.413528459845111e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 9.318340744357556e-05\n",
            "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7167e-05Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 9.306079300586134e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 9.266127744922414e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 9.241414227290079e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 9.176890307571739e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 9.16961653274484e-05\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6157e-05Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 9.190247510559857e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 9.149945253739133e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 9.161109483102337e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 9.134869469562545e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 9.150533878710121e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 9.121888433583081e-05\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.5229e-05Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 9.086359204957262e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 9.072514512808993e-05\n",
            "Finished epoch 12\n",
            "Train loss: 9.072514512808993e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.4824e-05\n",
            "Starting epoch 13\n",
            "Epoch 14/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 8.119206904666498e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 285ms/step - loss: 8.1192e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 8.515271474607289e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 8.346676622750238e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 8.02699287305586e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 8.149988570949063e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 8.221124880947173e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 8.272224658867344e-05\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2359e-05  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 8.294463623315096e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 8.284435170935467e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 8.338497718796134e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 8.339355554198846e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 8.439065277343616e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 8.491563494317234e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2953e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 8.428805449511856e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 8.29452183097601e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 8.23303998913616e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 8.16129322629422e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 8.128026820486411e-05\n",
            "\u001b[1m18/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2825e-05Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 8.116286335280165e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 8.080277621047571e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 8.113392686937004e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 8.06195821496658e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 8.054638601606712e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 8.022848487598822e-05\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2306e-05Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 7.966246630530804e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 7.977693894645199e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 7.954154716571793e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 7.944904791656882e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 7.928278500912711e-05\n",
            "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1829e-05Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 7.939648639876395e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 7.930574793135747e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 7.931290747364983e-05\n",
            "Finished epoch 13\n",
            "Train loss: 7.931290747364983e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.1527e-05\n",
            "Starting epoch 14\n",
            "Epoch 15/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 7.655254012206569e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 305ms/step - loss: 7.6553e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 7.308828935492784e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 7.31150503270328e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 7.554372132290155e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 7.567777356598526e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 7.599696982651949e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 7.456876483047381e-05\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4935e-05  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 7.375422865152359e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 7.42575793992728e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 7.337530405493453e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 7.275940879480913e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 7.243868458317593e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 7.279508281499147e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4148e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 7.331360393436626e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 7.327376079047099e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 7.260126585606486e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 7.224986620713025e-05\n",
            "\u001b[1m17/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.3845e-05Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 7.233196083689108e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 7.241629646159708e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 7.233972428366542e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 7.191631448222324e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 7.158369407989085e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 7.117402856238186e-05\n",
            "\u001b[1m23/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.3353e-05Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 7.056055619614199e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 7.041371281957254e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 7.051651482470334e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 7.02252727933228e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 6.983702041907236e-05\n",
            "\u001b[1m28/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.2810e-05Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 7.005135557847098e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 7.018233009148389e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 6.992564885877073e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 6.996023876126856e-05\n",
            "Finished epoch 14\n",
            "Train loss: 6.996023876126856e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 7.2387e-05\n",
            "Starting epoch 15\n",
            "Epoch 16/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 7.797816942911595e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 288ms/step - loss: 7.7978e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 7.635208021383733e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 7.267014734679833e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 6.730380118824542e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 6.611760181840509e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 6.529971142299473e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 6.496160494862124e-05\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.0098e-05  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 6.340405525406823e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 6.400392157956958e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 6.431744259316474e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 6.371521158143878e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 6.339112587738782e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 6.304250564426184e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.7120e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 6.34493917459622e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 6.365469744196162e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 6.352317723212764e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 6.32695882814005e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 6.309793388936669e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 6.341627886286005e-05\n",
            "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5946e-05Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 6.296880746958777e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 6.301073881331831e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 6.290253804763779e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 6.245966505957767e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 6.262635724851862e-05\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5289e-05Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 6.237076013348997e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 6.244370888452977e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 6.245031545404345e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 6.233249587239698e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 6.200671487022191e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 6.199445488164201e-05\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4685e-05Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 6.21299768681638e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 6.213845335878432e-05\n",
            "Finished epoch 15\n",
            "Train loss: 6.213845335878432e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.4453e-05\n",
            "Starting epoch 16\n",
            "Epoch 17/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 5.801945007988252e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 313ms/step - loss: 5.8019e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 5.536165554076433e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 5.527969915419817e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 5.671813414664939e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 5.7430566812399775e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 5.755584788857959e-05\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.6728e-05 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 5.7292079873150215e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 5.5867254559416324e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 5.561031139222905e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 5.631925887428224e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 5.6125165428966284e-05\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.6507e-05Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 5.657118163071573e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 5.6800574384396896e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 5.7200926676159725e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 5.7057961384998634e-05\n",
            "\u001b[1m15/32\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.6614e-05Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 5.7082565035670996e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 5.70349620829802e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 5.685209544026293e-05\n",
            "\u001b[1m18/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.6677e-05Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 5.65008886042051e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 5.648061051033437e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 5.604142279480584e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 5.615398913505487e-05\n",
            "\u001b[1m22/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.6607e-05Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 5.594527465291321e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 5.592764136963524e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 5.578352647717111e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 5.56217237317469e-05\n",
            "\u001b[1m26/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.6486e-05Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 5.551949288928881e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 5.5355860240524635e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 5.533950024982914e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 5.515775046660565e-05\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.6334e-05Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 5.5560743930982426e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 5.560026693274267e-05\n",
            "Finished epoch 16\n",
            "Train loss: 5.560026693274267e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5.6266e-05\n",
            "Starting epoch 17\n",
            "Epoch 18/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 5.3141753596719354e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 172ms/step - loss: 5.3142e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 4.8635043640388176e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 4.882723806076683e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 4.953509051119909e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 4.932652154820971e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 5.142148074810393e-05\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.0148e-05 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 4.9884594773175195e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 5.072448038845323e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 5.012085603084415e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 5.0446775276213884e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 5.1296825404278934e-05\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.0306e-05Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 5.184120891499333e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 5.188651994103566e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 5.195861012907699e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 5.189054718357511e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 5.161095396033488e-05\n",
            "\u001b[1m16/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.0784e-05Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 5.1119957788614556e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 5.1268005336169153e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 5.144562237546779e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 5.1335500756977126e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 5.114377927384339e-05\n",
            "\u001b[1m21/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.0898e-05Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 5.101090209791437e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 5.0921629735967144e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 5.106091339257546e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 5.084338772576302e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 5.0722672312986106e-05\n",
            "\u001b[1m26/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.0901e-05Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 5.079040420241654e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 5.0756148993968964e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 5.065714867669158e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 5.0389371608616784e-05\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.0867e-05Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 5.006788342143409e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 5.003107798984274e-05\n",
            "Finished epoch 17\n",
            "Train loss: 5.003107798984274e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.0792e-05\n",
            "Starting epoch 18\n",
            "Epoch 19/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 4.665796222980134e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 228ms/step - loss: 4.6658e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 4.5817767386324704e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 4.52037675131578e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 4.3844956962857395e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 4.370805618236773e-05\n",
            "\u001b[1m 5/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.5047e-05 Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 4.442160206963308e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 4.5946570025989786e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 4.650263872463256e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 4.681036080000922e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 4.6960401959950104e-05\n",
            "\u001b[1m10/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.5587e-05Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 4.648317917599343e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 4.61865020042751e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 4.600905594998039e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 4.627031012205407e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 4.611507756635547e-05\n",
            "\u001b[1m15/32\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.5796e-05Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 4.595469727064483e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 4.572720354190096e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 4.562798130791634e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 4.556886779027991e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 4.556311250780709e-05\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.5769e-05Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 4.562370668281801e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 4.539751535048708e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 4.555096529657021e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 4.5429824240272865e-05\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.5724e-05Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 4.53052889497485e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 4.521071241470054e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 4.5163433242123574e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 4.536120832199231e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 4.5180033339420334e-05\n",
            "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.5641e-05Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 4.523183815763332e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 4.524064206634648e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 4.524822725215927e-05\n",
            "Finished epoch 18\n",
            "Train loss: 4.524822725215927e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 4.5593e-05\n",
            "Starting epoch 19\n",
            "Epoch 20/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 4.525466647464782e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 223ms/step - loss: 4.5255e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 4.277764310245402e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 4.257291948306374e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 4.130317029193975e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 4.050184361403808e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 4.038356200908311e-05\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.2132e-05 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 4.045711102662608e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 4.002287096227519e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 4.0223851101472974e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 3.9842001569923013e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 3.989740798715502e-05\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.1203e-05Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 4.006797826150432e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 3.9692866266705096e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 3.990875120507553e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 3.9873746572993696e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 4.026888927910477e-05\n",
            "\u001b[1m16/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.0816e-05Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 4.027431714348495e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 4.054975215694867e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 4.07648622058332e-05\n",
            "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.0770e-05Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 4.0912233089329675e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 4.108301436644979e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 4.140752207604237e-05\n",
            "\u001b[1m22/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.0820e-05Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 4.1644085285952315e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 4.14428832300473e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 4.14848982472904e-05\n",
            "\u001b[1m25/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0905e-05Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 4.142824764130637e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 4.134932896704413e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 4.126955900574103e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 4.112621900276281e-05\n",
            "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.0958e-05Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 4.112151873414405e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 4.116080526728183e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 4.1146588046103716e-05\n",
            "Finished epoch 19\n",
            "Train loss: 4.1146588046103716e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 4.0981e-05\n",
            "Starting epoch 20\n",
            "Epoch 21/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 4.6621018555015326e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 144ms/step - loss: 4.6621e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 4.3183667003177106e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 4.0657425415702164e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 4.011452620034106e-05\n",
            "\u001b[1m 4/32\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.2644e-05 Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 3.9656017179368064e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 3.9294991438509896e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 3.907425707438961e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 3.871099397656508e-05\n",
            "\u001b[1m 8/32\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 4.0914e-05Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 3.8291720557026565e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 3.815181116806343e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 3.786536763072945e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 3.777363235712983e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 3.793425639742054e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.9795e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 3.780247061513364e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 3.807549364864826e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 3.780000042752363e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 3.7642505049007013e-05\n",
            "\u001b[1m17/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.9332e-05Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 3.734386700671166e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 3.7597808841383085e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 3.763894346775487e-05\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.9062e-05Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 3.737311635632068e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 3.723546979017556e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 3.705010385601781e-05\n",
            "\u001b[1m23/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.8821e-05Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 3.722199471667409e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 3.731686229002662e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 3.717588697327301e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 3.734919664566405e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 3.7439858715515584e-05\n",
            "\u001b[1m28/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.8550e-05Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 3.7542893551290035e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 3.750966425286606e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 3.7452453398145735e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 3.758030288736336e-05\n",
            "Finished epoch 20\n",
            "Train loss: 3.758030288736336e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3.8396e-05\n",
            "Starting epoch 21\n",
            "Epoch 22/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 3.564720827853307e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 3.5647e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 3.542847480275668e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 3.55420088453684e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 3.6654630093835294e-05\n",
            "\u001b[1m 4/32\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.5818e-05 Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 3.628757986007258e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 3.720220411196351e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 3.720031963894144e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 3.73290604329668e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 3.675011612358503e-05\n",
            "\u001b[1m 9/32\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6449e-05Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 3.654058673419058e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 3.653024396044202e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 3.643310992629267e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 3.6417706724023446e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6459e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 3.634731183410622e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 3.612362706917338e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 3.5808920074487105e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 3.561939229257405e-05\n",
            "\u001b[1m17/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6345e-05Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 3.57907047146e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 3.577754250727594e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 3.567705425666645e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 3.562313941074535e-05\n",
            "\u001b[1m21/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6225e-05Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 3.548055610735901e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 3.5210290661780164e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 3.50787267962005e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 3.497334546409547e-05\n",
            "\u001b[1m25/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.6059e-05Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 3.50642112607602e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 3.486530840746127e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 3.485686465865001e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 3.4732031053863466e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 3.452900273259729e-05\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.5851e-05Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 3.436904808040708e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 3.443465175223537e-05\n",
            "Finished epoch 21\n",
            "Train loss: 3.443465175223537e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 3.5720e-05\n",
            "Starting epoch 22\n",
            "Epoch 23/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 2.5377197744091973e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 2.5377e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 2.9501245080609806e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 3.2041818485595286e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 3.133039717795327e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 3.1790725188329816e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 3.187015317962505e-05\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.0319e-05Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 3.190467759850435e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 3.217898483853787e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 3.210972136002965e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 3.241555532440543e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 3.220052894903347e-05\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.1156e-05Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 3.280528835603036e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 3.296469003544189e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 3.2788819225970656e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 3.290791573817842e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 3.304889833088964e-05\n",
            "\u001b[1m16/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.1702e-05Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 3.2865864341147244e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 3.272670801379718e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 3.276977804489434e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 3.2524705602554604e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 3.2369905966334045e-05\n",
            "\u001b[1m21/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.1928e-05Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 3.2416141038993374e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 3.2365689548896626e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 3.228405330446549e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 3.221524821128696e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 3.204068707418628e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 3.2032574381446466e-05\n",
            "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.1994e-05Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 3.201506842742674e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 3.188168193446472e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 3.170719719491899e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 3.1705425499239936e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 3.164519148413092e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.1963e-05Finished epoch 22\n",
            "Train loss: 3.164519148413092e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.1953e-05\n",
            "Starting epoch 23\n",
            "Epoch 24/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 2.925858825619798e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 259ms/step - loss: 2.9259e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 3.093752820859663e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 3.10729919874575e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 3.105109135503881e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 3.044744698854629e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 2.99224575428525e-05\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.0448e-05 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 2.981850047945045e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 3.039126386283897e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 3.0711609724676237e-05\n",
            "\u001b[1m 9/32\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0401e-05Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 3.061811003135517e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 3.072942854487337e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 3.063571421080269e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 3.046446363441646e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.0466e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 3.0487673939205706e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 3.0310495276353322e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 3.030538937309757e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 2.998520722030662e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 3.000155084009748e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 2.9971917683724314e-05\n",
            "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.0375e-05Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 2.9990949769853614e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 3.0002473067725077e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 2.9798993637086824e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 2.9752178306807764e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 2.9546237783506513e-05\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.0259e-05Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 2.946772838186007e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 2.9424794774968177e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 2.934789881692268e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 2.9306447686394677e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 2.9220289434306324e-05\n",
            "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.0103e-05Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 2.9206019462435506e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 2.9229138817754574e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 2.9213440939201973e-05\n",
            "Finished epoch 23\n",
            "Train loss: 2.9213440939201973e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.9995e-05\n",
            "Starting epoch 24\n",
            "Epoch 25/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 2.5639299565227702e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 236ms/step - loss: 2.5639e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 2.7283964300295338e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 2.7883186703547835e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 2.8496311642811634e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 2.75770671578357e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 2.7385474822949618e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 2.6814206648850814e-05\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7297e-05  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 2.6712687031249516e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 2.711039451241959e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 2.7116368073620833e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 2.710367516556289e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 2.727839455474168e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 2.731732456595637e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7209e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 2.726356433413457e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 2.7223284632782452e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 2.7279298592475243e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 2.728860272327438e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 2.7056106773670763e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 2.6970688850269653e-05\n",
            "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7200e-05Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 2.698310163395945e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 2.7108821086585522e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 2.703351856325753e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 2.700274853850715e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 2.7012021746486425e-05\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7164e-05Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 2.6991174308932386e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 2.695489820325747e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 2.691922964004334e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 2.7003234208677895e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 2.709299405978527e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 2.711628985707648e-05\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7134e-05Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 2.7107225832878612e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 2.7052890800405294e-05\n",
            "Finished epoch 24\n",
            "Train loss: 2.7052890800405294e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 2.7128e-05\n",
            "Starting epoch 25\n",
            "Epoch 26/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 2.3745145881548524e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 295ms/step - loss: 2.3745e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 2.4831530026858672e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 2.532050530135166e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 2.4919094357755966e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 2.5201390599249862e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 2.5350796931888908e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 2.512063474569004e-05\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4927e-05  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 2.4930302970460616e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 2.5233315682271495e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 2.5254932552343234e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 2.4966951968963258e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 2.5397319404873997e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 2.5446581275900826e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5055e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 2.5581888621672988e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 2.5655386707512662e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 2.5545912649249658e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 2.5652361728134565e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 2.5605106202419847e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 2.5625917260185815e-05\n",
            "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5231e-05Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 2.5688204914331436e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 2.5685263608465903e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 2.5697263481561095e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 2.55528084380785e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 2.5318111511296593e-05\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5305e-05Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 2.5145756808342412e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 2.5208204533555545e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 2.519485860830173e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 2.523932562326081e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 2.5232673579012044e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 2.5169638320221566e-05\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5284e-05Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 2.5115568860201165e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 2.5129982532234862e-05\n",
            "Finished epoch 25\n",
            "Train loss: 2.5129982532234862e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.5269e-05\n",
            "Starting epoch 26\n",
            "Epoch 27/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 2.5985620595747605e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 295ms/step - loss: 2.5986e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 2.437270995869767e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 2.3824301024433225e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 2.388370194239542e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 2.4346330974367447e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 2.4351567844860256e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 2.427989056741353e-05\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4435e-05  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 2.396944364591036e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 2.3992544811335392e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 2.3683578547206707e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 2.3360742488875985e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 2.319499799341429e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 2.3659560611122288e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4070e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 2.3786777092027478e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 2.365443106100429e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 2.3496095309383236e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 2.360121470701415e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 2.3776978196110576e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 2.356813638471067e-05\n",
            "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3936e-05Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 2.363325620535761e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 2.37971507885959e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 2.374505129409954e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 2.3815384338377044e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 2.3751927074044943e-05\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.3897e-05Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 2.37295389524661e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 2.3680418962612748e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 2.3544815121567808e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 2.3495926143368706e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 2.3490902094636112e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 2.349139867874328e-05\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3832e-05 Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 2.337235309823882e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 2.338994454476051e-05\n",
            "Finished epoch 26\n",
            "Train loss: 2.338994454476051e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.3791e-05\n",
            "Starting epoch 27\n",
            "Epoch 28/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 2.460774157952983e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 2.4608e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 2.2023275960236788e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 2.2143600290291943e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 2.1156145521672443e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 2.1125710190972313e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 2.122038131346926e-05\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.2046e-05Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 2.1147483494132757e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 2.1484751414391212e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 2.133165435225237e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 2.149918145732954e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 2.1286481569404714e-05\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1730e-05Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 2.135555405402556e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 2.116385985573288e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 2.116926589224022e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 2.113767732225824e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 2.115445204253774e-05\n",
            "\u001b[1m16/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1563e-05Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 2.1446023311000317e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 2.143976598745212e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 2.1598329112748615e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 2.1754176486865617e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 2.180280898755882e-05\n",
            "\u001b[1m21/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1574e-05Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 2.1877727704122663e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 2.1828249373356812e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 2.1797457520733587e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 2.1796649889438413e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 2.1786436263937503e-05\n",
            "\u001b[1m26/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1621e-05Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 2.17286724364385e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 2.1811623810208403e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 2.1802801711601205e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 2.184261757065542e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 2.184300137741957e-05\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.1650e-05Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 2.1817138986079954e-05\n",
            "Finished epoch 27\n",
            "Train loss: 2.1817138986079954e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1661e-05\n",
            "Starting epoch 28\n",
            "Epoch 29/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 2.17972083191853e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 255ms/step - loss: 2.1797e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 2.158382994821295e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 2.051142837444786e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 2.0404293536557816e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 2.007962393690832e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 2.0807749024243094e-05\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0864e-05 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 2.047088673862163e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 2.0338831745903008e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 2.0405324903549626e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 2.0468418370001018e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 2.0409883290994912e-05\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0662e-05Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 2.0812973161810078e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 2.083789513562806e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 2.0947845769114792e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 2.0829345885431394e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 2.0928091544192284e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 2.0851302906521596e-05\n",
            "\u001b[1m17/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0734e-05Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 2.0809098714380525e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 2.0880315787508152e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 2.083487925119698e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 2.0778286852873862e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 2.0653507817769423e-05\n",
            "\u001b[1m22/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0747e-05Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 2.0667934222728945e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 2.0746390873682685e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 2.0766176021425053e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 2.0673060134868138e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 2.055650475085713e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 2.0444973415578716e-05\n",
            "\u001b[1m28/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0725e-05Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 2.034437238762621e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 2.0395529645611532e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 2.0427291019586846e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 2.0411151126609184e-05\n",
            "Finished epoch 28\n",
            "Train loss: 2.0411151126609184e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.0675e-05\n",
            "Starting epoch 29\n",
            "Epoch 30/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 1.9699727999977767e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 287ms/step - loss: 1.9700e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 2.0719935491797514e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 2.009306444961112e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 2.0326975572970696e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 2.005493479373399e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 2.0094308638363145e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 1.9700471966643818e-05\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0098e-05  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 1.9668837921926752e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 1.9714781956281513e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 1.9494105799822137e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 1.9553153833840042e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 1.9499742847983725e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 1.9408220396144316e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9848e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 1.9417397197685204e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 1.9414022972341627e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 1.9481714844005182e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 1.943169263540767e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 1.9619532395154238e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 1.956652704393491e-05\n",
            "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9735e-05Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 1.9561692170100287e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 1.9529561541276053e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 1.9458693714113906e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 1.9494365915306844e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 1.9407443687669e-05\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9684e-05Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 1.9373044779058546e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 1.9371069356566295e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 1.9219613022869453e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 1.9259310647612438e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 1.9223878553020768e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 1.9180226445314474e-05\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9601e-05Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 1.91372510016663e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 1.912743755383417e-05\n",
            "Finished epoch 29\n",
            "Train loss: 1.912743755383417e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.9558e-05\n",
            "Starting epoch 30\n",
            "Epoch 31/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 2.0206560293445364e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 292ms/step - loss: 2.0207e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 2.0091290934942663e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 1.9535473256837577e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 1.923626405186951e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 1.898721166071482e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 1.914909626066219e-05\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9534e-05 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 1.9042448911932297e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 1.8869843188440427e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 1.877827526186593e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 1.87136229214957e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 1.8613895008456893e-05\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9202e-05Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 1.8735414414550178e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 1.848775900725741e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 1.8447512047714554e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 1.8345595890423283e-05\n",
            "\u001b[1m15/32\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9016e-05Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 1.8209198969998397e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 1.8187269233749248e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 1.8283357348991558e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 1.8384955183137208e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 1.823878483264707e-05\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8827e-05Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 1.816147232602816e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 1.8078266293741763e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 1.818587043089792e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 1.8188344256486744e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 1.815772702684626e-05\n",
            "\u001b[1m25/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8693e-05Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 1.8152883058064617e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 1.8056640328723006e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 1.8004493540502153e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 1.8001672287937254e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 1.799817619030364e-05\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8584e-05Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 1.7988822946790606e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 1.795655771275051e-05\n",
            "Finished epoch 30\n",
            "Train loss: 1.795655771275051e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.8528e-05\n",
            "Starting epoch 31\n",
            "Epoch 32/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 1.6580865121795796e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 258ms/step - loss: 1.6581e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 1.6319956557708792e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 1.7498479792266153e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 1.7332073184661567e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 1.709499156277161e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 1.6992022210615687e-05\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.6970e-05 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 1.674156192166265e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 1.657846587477252e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 1.676388092164416e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 1.6688689356669784e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 1.68256665347144e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 1.688083830231335e-05\n",
            "\u001b[1m12/32\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6858e-05Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 1.684509334154427e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 1.6865287761902437e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 1.674132545304019e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 1.673464612395037e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 1.684487324382644e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 1.6953132217167877e-05\n",
            "\u001b[1m18/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6849e-05Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 1.7002414097078145e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 1.700215580058284e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 1.692468867986463e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 1.6872842024895363e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 1.691748548182659e-05\n",
            "\u001b[1m23/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6870e-05Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 1.6927215256146155e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 1.6964715541689657e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 1.6899010006454773e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 1.689516102487687e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 1.6910782505874522e-05\n",
            "\u001b[1m28/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6879e-05Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 1.690427234279923e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 1.6919360859901644e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 1.6900652553886175e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 1.689020973572042e-05\n",
            "Finished epoch 31\n",
            "Train loss: 1.689020973572042e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.6882e-05\n",
            "Starting epoch 32\n",
            "Epoch 33/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 1.5834084479138255e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 278ms/step - loss: 1.5834e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 1.5143954442464747e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 1.586306098033674e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 1.6125950423884206e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 1.629861435503699e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 1.601090480107814e-05\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5879e-05 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 1.606211662874557e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 1.6114556274260394e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 1.6180640159291215e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 1.605670331628062e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 1.608055754331872e-05\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.5979e-05Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 1.6113403034978546e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 1.6107953342725523e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 1.614553366380278e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 1.619571958144661e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 1.6112602679640986e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 1.60884483193513e-05\n",
            "\u001b[1m17/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6031e-05Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 1.612854794075247e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 1.6135594705701806e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 1.6129253708641045e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 1.6079688066383824e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 1.603982127562631e-05\n",
            "\u001b[1m22/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6048e-05Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 1.601410076546017e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 1.6024589058361016e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 1.599037932464853e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 1.592437365616206e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 1.592165972397197e-05\n",
            "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.6034e-05Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 1.5893729141680524e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 1.588844861544203e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 1.5907584383967333e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 1.5895569958956912e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 1.5918743883958086e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.6013e-05Finished epoch 32\n",
            "Train loss: 1.5918743883958086e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1.6010e-05\n",
            "Starting epoch 33\n",
            "Epoch 34/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 1.5360485122073442e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 263ms/step - loss: 1.5360e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 1.518092722108122e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 1.4986521819082554e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 1.457721009501256e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 1.4447056855715346e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 1.4587097211915534e-05\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.4857e-05 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 1.4502228623314295e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 1.4573772205039859e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 1.4908782759448513e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 1.4977452337916475e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 1.4996136087574996e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 1.4839253708487377e-05\n",
            "\u001b[1m12/32\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4828e-05Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 1.4951968296372797e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 1.493647232564399e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 1.4883419680700172e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 1.4755324627913069e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 1.4728614587511402e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 1.4807218576606829e-05\n",
            "\u001b[1m18/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4833e-05Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 1.4875578926876187e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 1.4918075066816527e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 1.4864317563478835e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 1.490074282628484e-05\n",
            "\u001b[1m22/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4844e-05Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 1.4819666830589995e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 1.4750607078894973e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 1.4783435290155467e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 1.4795655260968488e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 1.4850516890874133e-05\n",
            "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4836e-05Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 1.4878736692480743e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 1.4889562407915946e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 1.4954118341847789e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 1.4994425328040961e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 1.5012801668490283e-05\n",
            "Finished epoch 33\n",
            "Train loss: 1.5012801668490283e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.4858e-05\n",
            "Starting epoch 34\n",
            "Epoch 35/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 1.3088878404232673e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 281ms/step - loss: 1.3089e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 1.4084919712331612e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 1.5122971490200143e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 1.5172447092481889e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 1.4988147995609324e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 1.4996996469562873e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 1.4949119758966845e-05\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4629e-05  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 1.4838944480288774e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 1.4782475773245096e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 1.4844919860479422e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 1.4831504813628271e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 1.4881076822348405e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 1.4683782865176909e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4713e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 1.463875287299743e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 1.4549338629876729e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 1.4530877706420142e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 1.4449048649112228e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 1.4492117770714685e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 1.4424962500925176e-05\n",
            "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4650e-05Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 1.4373846170201432e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 1.433331908629043e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 1.4415851183002815e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 1.4440500308410265e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 1.4402335182239767e-05\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4597e-05Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 1.4421974810829852e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 1.432614226359874e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 1.4352387552207801e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 1.4351036043080967e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 1.4295028449851088e-05\n",
            "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4554e-05Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 1.4248807019612286e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 1.41907949000597e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 1.4190022739057895e-05\n",
            "Finished epoch 34\n",
            "Train loss: 1.4190022739057895e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.4512e-05\n",
            "Starting epoch 35\n",
            "Epoch 36/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 1.3774353647022508e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 1.3774e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 1.3678530194738414e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 1.3332083653949667e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 1.3324173778528348e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 1.3169183148420416e-05\n",
            "\u001b[1m 5/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3456e-05Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 1.3344200851861387e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 1.3460256923281122e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 1.3555055375036318e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 1.3576613127952442e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 1.351796709059272e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 1.379361765430076e-05\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3502e-05Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 1.383050130243646e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 1.3776589184999466e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 1.3811230928695295e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 1.3696263522433583e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 1.3624497114506084e-05\n",
            "\u001b[1m16/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.3579e-05Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 1.374079511151649e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 1.3755245163338259e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 1.373316172248451e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 1.3660358490596991e-05\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3608e-05Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 1.3714822671317961e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 1.3727162695431616e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 1.3663967365573626e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 1.3586461136583239e-05\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3619e-05Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 1.3524895621230826e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 1.3438182577374391e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 1.3457615750667173e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 1.3440248039842118e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 1.34628107844037e-05\n",
            "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.3592e-05Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 1.3465009942592587e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 1.344253178103827e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 1.3421869880403392e-05\n",
            "Finished epoch 35\n",
            "Train loss: 1.3421869880403392e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.3573e-05\n",
            "Starting epoch 36\n",
            "Epoch 37/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 1.2307449651416391e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 1.2307e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 1.2975914614798967e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 1.319037710345583e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 1.3190889148972929e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 1.3102018783683889e-05\n",
            "\u001b[1m 5/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.2953e-05Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 1.2862594303442165e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 1.2973878256161697e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 1.3078640222374815e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 1.3071909961581696e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 1.3097569535602815e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 1.3106776350468863e-05\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2996e-05Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 1.3031311937083956e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 1.2991494259040337e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 1.2928806427225936e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 1.296458958677249e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 1.2988091839361005e-05\n",
            "\u001b[1m16/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2991e-05Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 1.3017014680372085e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 1.2979933671886101e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 1.2932746358274017e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 1.294944104301976e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 1.282543598790653e-05\n",
            "\u001b[1m21/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2979e-05Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 1.2842417163483333e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 1.2759724086208735e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 1.2787786545231938e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 1.2773758498951793e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 1.2731108654406853e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 1.277585033676587e-05\n",
            "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2935e-05Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 1.272245299333008e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 1.2697350939561147e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 1.2696615158347413e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 1.2708614121947903e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 1.2720639460894745e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.2899e-05Finished epoch 36\n",
            "Train loss: 1.2720639460894745e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.2894e-05\n",
            "Starting epoch 37\n",
            "Epoch 38/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 1.3133435459167231e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 240ms/step - loss: 1.3133e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 1.2996545592613984e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 1.2462035556382034e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 1.2345508366706781e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 1.2412898286129348e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 1.2326067917456385e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 1.2469621651689522e-05\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2592e-05  Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 1.24594535009237e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 1.2195249837532174e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 1.2225061254866887e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 1.2161835002189036e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 1.2227256775076967e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 1.2257331036380492e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2436e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 1.235778381669661e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 1.2296945897105616e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 1.2332027836237103e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 1.2273841093701776e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 1.2268543287063949e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 1.2256065019755624e-05\n",
            "\u001b[1m19/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2393e-05Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 1.2371276170597412e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 1.2264544238860253e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 1.2202676771266852e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 1.2186776075395755e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 1.2226318176544737e-05\n",
            "\u001b[1m24/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2363e-05Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 1.2225682439748198e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 1.2190376764920074e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 1.2175833035144024e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 1.2156866432633251e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 1.2138380043325014e-05\n",
            "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2331e-05Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 1.2117572623537853e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 1.2054911167069804e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 1.2069794138369616e-05\n",
            "Finished epoch 37\n",
            "Train loss: 1.2069794138369616e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1.2300e-05\n",
            "Starting epoch 38\n",
            "Epoch 39/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 1.159881503554061e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 1.1599e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 1.1836609701276757e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 1.1921835721295793e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 1.1675083442241885e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 1.1634070688160136e-05\n",
            "\u001b[1m 5/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1733e-05Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 1.1530471965670586e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 1.1595632713579107e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 1.1519765394041315e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 1.1606465704971924e-05\n",
            "\u001b[1m 9/32\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1658e-05Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 1.1631592315097805e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 1.1654031368379947e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 1.167774826171808e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 1.1671878382912837e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 1.162909666163614e-05\n",
            "\u001b[1m14/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1656e-05Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 1.1564991837076377e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 1.144408179243328e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 1.1440971320553217e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 1.1516292943269946e-05\n",
            "\u001b[1m18/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1619e-05Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 1.1487964002299123e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 1.1557691323105246e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 1.1553284821275156e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 1.159420844487613e-05\n",
            "\u001b[1m22/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1606e-05Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 1.160911597253289e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 1.1649962289084215e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 1.1644765436358284e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 1.1601634469116107e-05\n",
            "\u001b[1m26/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1610e-05Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 1.1556278877833392e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 1.1520652151375543e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 1.1541750609467272e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 1.1505806469358504e-05\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1599e-05Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 1.1464352610346396e-05\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 1.1461050235084258e-05\n",
            "Finished epoch 38\n",
            "Train loss: 1.1461050235084258e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1587e-05\n",
            "Starting epoch 39\n",
            "Epoch 40/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 1.0294955245626625e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 179ms/step - loss: 1.0295e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 9.5897867140593e-06\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 1.0120090337295551e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 1.0321537047275342e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 1.0757379641290754e-05\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 1.1001521670550574e-05\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0348e-05 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 1.1326984349580016e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 1.1057644769607577e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 1.097355652746046e-05\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 1.1021086720575113e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 1.1049884960812051e-05\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0683e-05Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 1.1057982192141935e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 1.1051088222302496e-05\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 1.1066133083659224e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 1.107809384848224e-05\n",
            "\u001b[1m15/32\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.0785e-05Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 1.1078395800723229e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 1.1039049240935128e-05\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 1.0998804100381676e-05\n",
            "\u001b[1m18/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0827e-05Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 1.1037169315386564e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 1.1015692507498898e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 1.1037297554139514e-05\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 1.10295441118069e-05\n",
            "\u001b[1m22/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0864e-05Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 1.09657794382656e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 1.0966793524858076e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 1.101834095607046e-05\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 1.0993074283760507e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 1.0974395991070196e-05\n",
            "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0886e-05Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 1.0936239050352015e-05\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 1.0894893421209417e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 1.0878117791435216e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 1.0888439646805637e-05\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0888e-05Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 1.0899145308940206e-05\n",
            "Finished epoch 39\n",
            "Train loss: 1.0899145308940206e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 1.0888e-05\n",
            "Starting epoch 40\n",
            "Epoch 41/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 1.0740066500147805e-05\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 168ms/step - loss: 1.0740e-05Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 1.0509735147934407e-05\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 1.0416092663945165e-05\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 1.0617778571031522e-05\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 1.0631573786668014e-05\n",
            "\u001b[1m 5/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0583e-05 Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 1.0793080036819447e-05\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 1.0848934834939428e-05\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 1.0719561942096334e-05\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 1.0923362424364313e-05\n",
            "\u001b[1m 9/32\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0689e-05Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 1.0868110621231608e-05\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 1.0888966244237963e-05\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 1.0809032573888544e-05\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 1.0666715752449818e-05\n",
            "\u001b[1m13/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.0726e-05Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 1.063686067936942e-05\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 1.0591334103082772e-05\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 1.0600967470963951e-05\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 1.0652109267539345e-05\n",
            "\u001b[1m17/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0701e-05Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 1.066918412107043e-05\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 1.0670994015526958e-05\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 1.0601210306049325e-05\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 1.0571749953669496e-05\n",
            "\u001b[1m21/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0687e-05Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 1.056673499988392e-05\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 1.0540257790125906e-05\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 1.054951371770585e-05\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 1.0525525794946589e-05\n",
            "\u001b[1m25/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0664e-05Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 1.049807087838417e-05\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 1.0459182703925762e-05\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 1.0407761692476925e-05\n",
            "\u001b[1m28/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0642e-05Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 1.039431390381651e-05\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 1.0396352081443183e-05\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 1.036761295836186e-05\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.0617e-05Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 1.037662059388822e-05\n",
            "Finished epoch 40\n",
            "Train loss: 1.037662059388822e-05\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 1.0603e-05\n",
            "Starting epoch 41\n",
            "Epoch 42/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 9.73314126895275e-06\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 697ms/step - loss: 9.7331e-06Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 9.580597179592587e-06\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 9.54617189563578e-06\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 9.66917650657706e-06\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 9.563837920723017e-06\n",
            "\u001b[1m 5/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.6186e-06  Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 9.50412231759401e-06\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 9.66867901297519e-06\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 9.732521903060842e-06\n",
            "\u001b[1m 8/32\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.6248e-06Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 9.723004041006789e-06\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 9.829333976085763e-06\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 9.946887985279318e-06\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 9.836268873186782e-06\n",
            "\u001b[1m12/32\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.6945e-06Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 9.758465239428915e-06\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 9.786990631255321e-06\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 9.793302524485625e-06\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 9.815729754336644e-06\n",
            "\u001b[1m16/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.7180e-06Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 9.811724339670036e-06\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 9.781252629181836e-06\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 9.779199899639934e-06\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 9.822016181715298e-06\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 9.7341e-06Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 9.793934623303358e-06\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 9.831896022660658e-06\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 9.836012395680882e-06\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 9.877791853796225e-06\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 9.842615327215753e-06\n",
            "\u001b[1m25/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.7546e-06Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 9.837674951995723e-06\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 9.864712410490029e-06\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 9.89458476396976e-06\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 9.906591913022567e-06\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 9.879290701064747e-06\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.7749e-06Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 9.89001364359865e-06\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 9.883871825877577e-06\n",
            "Finished epoch 41\n",
            "Train loss: 9.883871825877577e-06\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 9.7850e-06\n",
            "Starting epoch 42\n",
            "Epoch 43/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 8.725666702957824e-06\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 8.7257e-06Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 9.112382940656971e-06\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 9.027194209920708e-06\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 9.277260687667876e-06\n",
            "\u001b[1m 4/32\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.0356e-06Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 9.332489753433038e-06\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 9.344662430521566e-06\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 9.651821528677829e-06\n",
            "\u001b[1m 7/32\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.2102e-06Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 9.639788913773373e-06\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 9.587264685251284e-06\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 9.445819159736857e-06\n",
            "\u001b[1m10/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.3144e-06Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 9.330280590802431e-06\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 9.285199666919652e-06\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 9.337902156403288e-06\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 9.368034625367727e-06\n",
            "\u001b[1m14/32\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.3190e-06Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 9.365978257847019e-06\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 9.364333891426213e-06\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 9.393214895681012e-06\n",
            "\u001b[1m17/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.3288e-06Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 9.425679309060797e-06\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 9.416688953933772e-06\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 9.394197149958927e-06\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 9.36998549150303e-06\n",
            "\u001b[1m21/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.3427e-06Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 9.384040822624229e-06\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 9.434565072297119e-06\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 9.424281415704172e-06\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 9.418670742888935e-06\n",
            "\u001b[1m25/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.3543e-06Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 9.405218406755012e-06\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 9.394759217684623e-06\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 9.356962436868344e-06\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 9.373487955599558e-06\n",
            "\u001b[1m29/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.3582e-06Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 9.398705515195616e-06\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 9.421652976016048e-06\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 9.429742931388319e-06\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.3637e-06Finished epoch 42\n",
            "Train loss: 9.429742931388319e-06\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 9.3657e-06\n",
            "Starting epoch 43\n",
            "Epoch 44/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 9.266934284823947e-06\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 663ms/step - loss: 9.2669e-06Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 8.892910955182742e-06\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 8.883945156412665e-06\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 8.998536031867843e-06\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 9.059168405656237e-06\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 9.08448055270128e-06\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.0310e-06  Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 8.842343049764168e-06\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 8.882638212526217e-06\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 8.8425140347681e-06\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 8.857596185407601e-06\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 8.911539225664455e-06\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.9566e-06Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 8.884087947080843e-06\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 8.873947081156075e-06\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 8.96790879778564e-06\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 8.992812581709586e-06\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 8.941687156038824e-06\n",
            "\u001b[1m16/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.9489e-06Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 8.984392479760572e-06\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 8.929207979235798e-06\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 8.972868272394408e-06\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 9.037970812642016e-06\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 9.028721251524985e-06\n",
            "\u001b[1m21/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.9589e-06Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 8.996762517199386e-06\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 8.999859346658923e-06\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 9.02692863746779e-06\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 9.059424883162137e-06\n",
            "\u001b[1m25/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.9688e-06Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 9.064870027941652e-06\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 9.057378520083148e-06\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 9.03639283933444e-06\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 8.988744411908556e-06\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 9.004981620819308e-06\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 8.9791e-06Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 8.99583574209828e-06\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 9.002142178360373e-06\n",
            "Finished epoch 43\n",
            "Train loss: 9.002142178360373e-06\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.9810e-06\n",
            "Starting epoch 44\n",
            "Epoch 45/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 8.911913027986884e-06\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 242ms/step - loss: 8.9119e-06Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 8.754544978728518e-06\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 8.517486094206106e-06\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 8.524096301698592e-06\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 8.58755265653599e-06\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 8.55824055179255e-06\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.6423e-06 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 8.604231879871804e-06\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 8.590719517087564e-06\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 8.554051419196185e-06\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 8.515833542332985e-06\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 8.417882781941444e-06\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.5942e-06Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 8.4246830738266e-06\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 8.460524441034067e-06\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 8.453533155261539e-06\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 8.49411117087584e-06\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 8.61058560985839e-06\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 8.667325346323196e-06\n",
            "\u001b[1m17/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.5675e-06Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 8.72990676725749e-06\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 8.695094038557727e-06\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 8.722599886823446e-06\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 8.704015272087418e-06\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 8.735040864848997e-06\n",
            "\u001b[1m22/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.6015e-06Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 8.73616590979509e-06\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 8.765401616983581e-06\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 8.721163794689346e-06\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 8.698585588717833e-06\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 8.700655598659068e-06\n",
            "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.6243e-06Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 8.675683602632489e-06\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 8.652308679302223e-06\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 8.640625310363248e-06\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 8.623445864941459e-06\n",
            "\u001b[1m31/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.6274e-06Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 8.601889931014739e-06\n",
            "Finished epoch 44\n",
            "Train loss: 8.601889931014739e-06\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.6258e-06\n",
            "Starting epoch 45\n",
            "Epoch 46/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 7.665471457585227e-06\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 250ms/step - loss: 7.6655e-06Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 7.407707926176954e-06\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 8.077307938947342e-06\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 7.90280773799168e-06\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 8.089265975286253e-06\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 8.058862476900686e-06\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.8669e-06 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 8.2810456660809e-06\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 8.353636076208204e-06\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 8.283868737635203e-06\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 8.241055184043944e-06\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 8.310874363814946e-06\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 8.36364233691711e-06\n",
            "\u001b[1m12/32\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.0863e-06Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 8.346892172994558e-06\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 8.34205548017053e-06\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 8.397791134484578e-06\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 8.348038136318792e-06\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 8.359706953342538e-06\n",
            "\u001b[1m17/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.1665e-06Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 8.338178304256871e-06\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 8.361757863895036e-06\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 8.356067155546043e-06\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 8.358333616342861e-06\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 8.335457096109167e-06\n",
            "\u001b[1m22/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.2082e-06Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 8.317490937770344e-06\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 8.25355982669862e-06\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 8.279997018689755e-06\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 8.279531357402448e-06\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 8.269445061159786e-06\n",
            "\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.2215e-06Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 8.250633072748315e-06\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 8.277585948235355e-06\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 8.269410500361118e-06\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 8.245468961831648e-06\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 8.228455044445582e-06\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.2266e-06Finished epoch 45\n",
            "Train loss: 8.228455044445582e-06\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 8.2267e-06\n",
            "Starting epoch 46\n",
            "Epoch 47/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 7.1582644523005e-06\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 262ms/step - loss: 7.1583e-06Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 7.293251655937638e-06\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 7.678068868699484e-06\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 7.669478691241238e-06\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 7.747558811388444e-06\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 7.747074960207101e-06\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.5489e-06 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 7.692424333072267e-06\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 7.659227776457556e-06\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 7.755787009955384e-06\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 7.780368832754903e-06\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 7.83020459493855e-06\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 7.809957423887681e-06\n",
            "\u001b[1m12/32\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.6518e-06Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 7.819429811206646e-06\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 7.941825060697738e-06\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 7.976192136993632e-06\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 7.977443601703271e-06\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 8.007564247236587e-06\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 7.994888619577978e-06\n",
            "\u001b[1m18/32\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.7522e-06Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 7.989186997292563e-06\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 7.985318916325923e-06\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 7.944320714159403e-06\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 7.937120244605467e-06\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 7.918592018540949e-06\n",
            "\u001b[1m23/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.7962e-06Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 7.873200956964865e-06\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 7.885118066042196e-06\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 7.905835445853882e-06\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 7.89867863204563e-06\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 7.888040272518992e-06\n",
            "\u001b[1m28/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.8130e-06Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 7.87503449828364e-06\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 7.912543878774159e-06\n",
            "Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 7.890607776062097e-06\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 7.877824828028679e-06\n",
            "Finished epoch 46\n",
            "Train loss: 7.877824828028679e-06\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.8242e-06\n",
            "Starting epoch 47\n",
            "Epoch 48/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 6.426342224585824e-06\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 250ms/step - loss: 6.4263e-06Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 6.995950116106542e-06\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 7.22139293429791e-06\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 7.591172561660642e-06\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 7.742335583316162e-06\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 7.716288564552087e-06\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.2822e-06 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 7.691641258134041e-06\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 7.65426921134349e-06\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 7.5013585956185125e-06\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 7.493209523090627e-06\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 7.394843578367727e-06\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 7.421399004670093e-06\n",
            "\u001b[1m12/32\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.4042e-06Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 7.462031135219149e-06\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 7.430127425323008e-06\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 7.394037311314605e-06\n",
            "Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 7.39316783437971e-06\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 7.373284915956901e-06\n",
            "\u001b[1m17/32\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.4060e-06Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 7.42579368306906e-06\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 7.462866960850079e-06\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 7.4708777901832946e-06\n",
            "Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 7.522504347434733e-06\n",
            "\u001b[1m21/32\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.4183e-06Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 7.504680525016738e-06\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 7.5142997957300395e-06\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 7.4968083936255425e-06\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 7.501492291339673e-06\n",
            "Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 7.5269445005687885e-06\n",
            "\u001b[1m26/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.4357e-06Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 7.520196049881633e-06\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 7.53864651414915e-06\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 7.531953087891452e-06\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 7.544237632828299e-06\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.4488e-06Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 7.535987606388517e-06\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 7.547763289039722e-06\n",
            "Finished epoch 47\n",
            "Train loss: 7.547763289039722e-06\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.4574e-06\n",
            "Starting epoch 48\n",
            "Epoch 49/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 6.279502485995181e-06\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 247ms/step - loss: 6.2795e-06Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 6.822775503678713e-06\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 7.005919997027377e-06\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 7.133002782211406e-06\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 7.13048075340339e-06\n",
            "Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 7.239870228659129e-06\n",
            "\u001b[1m 6/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.9353e-06 Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 7.293393082363764e-06\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 7.349487987085013e-06\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 7.344945970544359e-06\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 7.295014711417025e-06\n",
            "Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 7.271945378306555e-06\n",
            "\u001b[1m11/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.1060e-06Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 7.272059065144276e-06\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 7.279285910044564e-06\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 7.294807346625021e-06\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 7.25953395885881e-06\n",
            "\u001b[1m15/32\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.1515e-06Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 7.250232556543779e-06\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 7.22781032891362e-06\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 7.2433476816513576e-06\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 7.243473191920202e-06\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 7.2120265031117015e-06\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.1724e-06Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 7.231927611428546e-06\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 7.2605034802109e-06\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 7.256126536958618e-06\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 7.245763754326617e-06\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 7.233389169414295e-06\n",
            "\u001b[1m25/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.1871e-06Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 7.185248250607401e-06\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 7.222795375128044e-06\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 7.22748200132628e-06\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 7.221742180263391e-06\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 7.225869921967387e-06\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.1920e-06Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 7.235435077745933e-06\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 7.235015345941065e-06\n",
            "Finished epoch 48\n",
            "Train loss: 7.235015345941065e-06\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.1959e-06\n",
            "Starting epoch 49\n",
            "Epoch 50/50\n",
            "Training: Starting batch 0\n",
            "Training: Finished batch 0\n",
            "Train loss: 6.509939794341335e-06\n",
            "\u001b[1m 1/32\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 230ms/step - loss: 6.5099e-06Training: Starting batch 1\n",
            "Training: Finished batch 1\n",
            "Train loss: 6.408123226719908e-06\n",
            "Training: Starting batch 2\n",
            "Training: Finished batch 2\n",
            "Train loss: 6.541843958984828e-06\n",
            "Training: Starting batch 3\n",
            "Training: Finished batch 3\n",
            "Train loss: 6.813333584432257e-06\n",
            "Training: Starting batch 4\n",
            "Training: Finished batch 4\n",
            "Train loss: 6.968674824747723e-06\n",
            "\u001b[1m 5/32\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.6484e-06 Training: Starting batch 5\n",
            "Training: Finished batch 5\n",
            "Train loss: 6.9836910370213445e-06\n",
            "Training: Starting batch 6\n",
            "Training: Finished batch 6\n",
            "Train loss: 6.987250344536733e-06\n",
            "Training: Starting batch 7\n",
            "Training: Finished batch 7\n",
            "Train loss: 6.921074600541033e-06\n",
            "Training: Starting batch 8\n",
            "Training: Finished batch 8\n",
            "Train loss: 6.883861260575941e-06\n",
            "Training: Starting batch 9\n",
            "Training: Finished batch 9\n",
            "Train loss: 6.901480901433388e-06\n",
            "\u001b[1m10/32\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.7919e-06Training: Starting batch 10\n",
            "Training: Finished batch 10\n",
            "Train loss: 6.895692877151305e-06\n",
            "Training: Starting batch 11\n",
            "Training: Finished batch 11\n",
            "Train loss: 6.925285106262891e-06\n",
            "Training: Starting batch 12\n",
            "Training: Finished batch 12\n",
            "Train loss: 6.964667591091711e-06\n",
            "Training: Starting batch 13\n",
            "Training: Finished batch 13\n",
            "Train loss: 6.963978194107767e-06\n",
            "Training: Starting batch 14\n",
            "Training: Finished batch 14\n",
            "Train loss: 6.986552307353122e-06\n",
            "\u001b[1m15/32\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.8437e-06Training: Starting batch 15\n",
            "Training: Finished batch 15\n",
            "Train loss: 6.961614417377859e-06\n",
            "Training: Starting batch 16\n",
            "Training: Finished batch 16\n",
            "Train loss: 7.0034934651630465e-06\n",
            "Training: Starting batch 17\n",
            "Training: Finished batch 17\n",
            "Train loss: 7.008465217950288e-06\n",
            "Training: Starting batch 18\n",
            "Training: Finished batch 18\n",
            "Train loss: 6.995340754656354e-06\n",
            "Training: Starting batch 19\n",
            "Training: Finished batch 19\n",
            "Train loss: 7.0228952608886175e-06\n",
            "\u001b[1m20/32\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.8824e-06Training: Starting batch 20\n",
            "Training: Finished batch 20\n",
            "Train loss: 7.0252822297334205e-06\n",
            "Training: Starting batch 21\n",
            "Training: Finished batch 21\n",
            "Train loss: 7.006073701631976e-06\n",
            "Training: Starting batch 22\n",
            "Training: Finished batch 22\n",
            "Train loss: 7.015386017883429e-06\n",
            "Training: Starting batch 23\n",
            "Training: Finished batch 23\n",
            "Train loss: 6.990104793658247e-06\n",
            "Training: Starting batch 24\n",
            "Training: Finished batch 24\n",
            "Train loss: 6.971465609240113e-06\n",
            "\u001b[1m25/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.9062e-06Training: Starting batch 25\n",
            "Training: Finished batch 25\n",
            "Train loss: 6.975266387598822e-06\n",
            "Training: Starting batch 26\n",
            "Training: Finished batch 26\n",
            "Train loss: 6.989817848079838e-06\n",
            "Training: Starting batch 27\n",
            "Training: Finished batch 27\n",
            "Train loss: 6.981045316933887e-06\n",
            "Training: Starting batch 28\n",
            "Training: Finished batch 28\n",
            "Train loss: 6.975715677981498e-06\n",
            "Training: Starting batch 29\n",
            "Training: Finished batch 29\n",
            "Train loss: 6.962216957617784e-06\n",
            "\u001b[1m30/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.9180e-06Training: Starting batch 30\n",
            "Training: Finished batch 30\n",
            "Train loss: 6.941333140275674e-06\n",
            "Training: Starting batch 31\n",
            "Training: Finished batch 31\n",
            "Train loss: 6.939611012057867e-06\n",
            "Finished epoch 49\n",
            "Train loss: 6.939611012057867e-06\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.9200e-06\n",
            "Finished training.\n"
          ]
        }
      ]
    }
  ]
}