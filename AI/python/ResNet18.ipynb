{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c6d93ee",
   "metadata": {},
   "source": [
    "[![Resnet-18ÁΩëÁªúÂõæÁ§∫ÁêÜËß£-ËÖæËÆØ‰∫ëÂºÄÂèëËÄÖÁ§æÂå∫ ...](https://images.openai.com/thumbnails/14f33d3ea70888832cd8776ec3955c42.png)](https://cloud.tencent.com/developer/article/2053549)\n",
    "\n",
    "To implement ResNet-18 using the `torchvision` package in PyTorch, you can utilize the pre-trained model provided by the library. Here's a step-by-step guide:\n",
    "\n",
    "### üß± 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11021cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bc98be",
   "metadata": {},
   "source": [
    "### üñºÔ∏è 2. Define Image Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787cdeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c20b124",
   "metadata": {},
   "source": [
    "### üì¶ 3. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ed5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53301c5e",
   "metadata": {},
   "source": [
    "### üß† 4. Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdf40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 10)  # Adjusting for CIFAR-10 classes\n",
    "model = model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6863e9",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è 5. Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f2bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a391a39c",
   "metadata": {},
   "source": [
    "### üöÄ 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d0ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d066487",
   "metadata": {},
   "source": [
    "### üìä 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Accuracy of the model on the 10,000 test images: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33312a2e",
   "metadata": {},
   "source": [
    "This implementation utilizes the pre-trained ResNet-18 model from `torchvision`, fine-tuning it for the CIFAR-10 dataset. The model is adjusted by modifying the fully connected layer (`model.fc`) to output 10 classes, corresponding to the CIFAR-10 dataset."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
